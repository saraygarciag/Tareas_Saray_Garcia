{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Participación decimas parcial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVWVRRHaNWGh2UgQSnz3lc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saraygarciag/Tareas_Saray_Garcia/blob/main/Participaci%C3%B3n_decimas_parcial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYbKp8QK3A7M"
      },
      "source": [
        "# **Saray Daniella García Gelves.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBqmUbFk2w5y"
      },
      "source": [
        "## **¿Cómo nos aseguramos que cuándo lleguen predicciones totalmente nuevas, el modelo vaya a generalizar y predecir bien eso que no conoce?¿Es posible realizar un paso extra asegurandose que exista un conjunto de datos que el modelo nunca vea y tener un conocimiento real sobre el ajuste del modelo?**\n",
        "\n",
        "\n",
        "### R:// Se asegura porque el modelo intenta memorizar el ruido en los datos de entrenamiento en lugar de intentar aprender patrones importantes en los datos. Además, la validación cruzada de k=10 veces significa que el procedimiento de validación cruzada ha promediado k conjuntos de puntuaciones de precisión al dividir el conjunto de datos en k pliegues diferentes. De esta manera, el modelo ve diferentes tipos de instancias (puntos de datos) en cada etapa de entrenamiento. Por lo tanto, el modelo tiene datos muy diferentes para aprender nuevos patrones. Por lo tanto, se generalizará bien para nuevos datos no vistos (datos de prueba)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXFAh8i96TSz"
      },
      "source": [
        "### El uso de la validación cruzada de k-fold en combinación con la búsqueda en cuadrícula es una estrategia muy útil para mejorar el rendimiento de un modelo de aprendizaje automático al ajustar los hiperparámetros del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hCrmRK4-hA9"
      },
      "source": [
        "### Podemos usar el **cross_val_score integrado** (devuelve el puntaje de cada prueba) / **corss_val_predict** (devuelve el puntaje predicho para cada observación en el conjunto de datos de entrada cuando era parte del conjunto de prueba) de la biblioteca scikit_learn.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLaiqCmh_QQf"
      },
      "source": [
        "skf = StratifiedKFold (n_splits = 3, random_state = None, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdTpFU8c7bRG"
      },
      "source": [
        "Fuentes: \n",
        "\n",
        "\n",
        "*   https://towardsdatascience.com/k-fold-cross-validation-explained-in-plain-english-659e33c0bc0\n",
        "*   https://towardsdatascience.com/how-to-mitigate-overfitting-with-k-fold-cross-validation-518947ed7428 \n",
        "\n",
        "\n"
      ]
    }
  ]
}